{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 0.6672493815422058,
      "learning_rate": 4.8e-05,
      "loss": 10.7399,
      "step": 5
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2425214648246765,
      "learning_rate": 4.55e-05,
      "loss": 10.7397,
      "step": 10
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7323281764984131,
      "learning_rate": 4.3e-05,
      "loss": 10.7404,
      "step": 15
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.33788642287254333,
      "learning_rate": 4.05e-05,
      "loss": 10.7399,
      "step": 20
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2374977022409439,
      "learning_rate": 3.8e-05,
      "loss": 10.7406,
      "step": 25
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5737268328666687,
      "learning_rate": 3.55e-05,
      "loss": 10.741,
      "step": 30
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.2790576219558716,
      "learning_rate": 3.3e-05,
      "loss": 10.7388,
      "step": 35
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2957782745361328,
      "learning_rate": 3.05e-05,
      "loss": 10.7385,
      "step": 40
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4754113554954529,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 10.7396,
      "step": 45
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.30994459986686707,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 10.7387,
      "step": 50
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.3899630904197693,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 10.7382,
      "step": 55
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.22944191098213196,
      "learning_rate": 2.05e-05,
      "loss": 10.7377,
      "step": 60
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.21473121643066406,
      "learning_rate": 1.8e-05,
      "loss": 10.7377,
      "step": 65
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.31591102480888367,
      "learning_rate": 1.55e-05,
      "loss": 10.7376,
      "step": 70
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.18811871111392975,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 10.7394,
      "step": 75
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5780987739562988,
      "learning_rate": 1.05e-05,
      "loss": 10.7376,
      "step": 80
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.15547727048397064,
      "learning_rate": 8.000000000000001e-06,
      "loss": 10.7369,
      "step": 85
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.3031315207481384,
      "learning_rate": 5.500000000000001e-06,
      "loss": 10.7383,
      "step": 90
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.587424635887146,
      "learning_rate": 3e-06,
      "loss": 10.7371,
      "step": 95
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2814560532569885,
      "learning_rate": 5.000000000000001e-07,
      "loss": 10.7382,
      "step": 100
    }
  ],
  "logging_steps": 5,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 23347200.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
